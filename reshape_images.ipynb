{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggmPInMqZ7aD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.2.7-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeJ8pHUkaJiO",
        "outputId": "f5c948c1-b00f-47d4-cc84-55e9b9f29a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting facenet_pytorch\n",
            "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (0.14.1+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (7.1.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (2022.12.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet_pytorch) (4.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet_pytorch) (1.13.1+cu116)\n",
            "Installing collected packages: facenet_pytorch\n",
            "Successfully installed facenet_pytorch-2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import glob\n",
        "import os\n",
        "import PIL.Image\n",
        "import six.moves.queue as Queue\n",
        "import threading\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import argparse\n",
        "import threading\n",
        "import six.moves.queue as Queue\n",
        "import traceback\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import PIL.Image"
      ],
      "metadata": {
        "id": "aI6DGX2kaNP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBucp_suaPsi",
        "outputId": "469179d5-65ba-4973-cbdc-ff7e6b5c5351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_landmarks(path_image):\n",
        "  # Create face detector\n",
        "  mtcnn = MTCNN(keep_all=True, device='cuda:0')\n",
        "\n",
        "  # Load a single image and display\n",
        "  img = Image.open(path_image)\n",
        "  img = np.asarray(img)\n",
        "  frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  frame = Image.fromarray(frame)\n",
        "\n",
        "  # Detect face\n",
        "  boxes, probs, landmarks = mtcnn.detect(frame, landmarks=True)\n",
        "  return landmarks"
      ],
      "metadata": {
        "id": "YoQvteOlaiR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_images(folder_path):\n",
        "    import scipy.ndimage\n",
        "\n",
        "    def rot90(v):\n",
        "        return np.array([-v[1], v[0]])\n",
        "\n",
        "    def process_func(img,lm):\n",
        "        # Choose oriented crop rectangle.\n",
        "        eye_avg = (lm[0] + lm[1]) * 0.5 + 0.5\n",
        "        mouth_avg = (lm[3] + lm[4]) * 0.5 + 0.5\n",
        "        eye_to_eye = lm[1] - lm[0]\n",
        "        eye_to_mouth = mouth_avg - eye_avg\n",
        "        x = eye_to_eye - rot90(eye_to_mouth)\n",
        "        x /= np.hypot(*x)\n",
        "        x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
        "        y = rot90(x)\n",
        "        c = eye_avg + eye_to_mouth * 0.1\n",
        "        quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
        "        zoom = 1024 / (np.hypot(*x) * 2)\n",
        "\n",
        "        # Shrink.\n",
        "        shrink = int(np.floor(0.5 / zoom))\n",
        "        if shrink > 1:\n",
        "            size = (int(np.round(float(img.size[0]) / shrink)), int(np.round(float(img.size[1]) / shrink)))\n",
        "            img = img.resize(size, PIL.Image.ANTIALIAS)\n",
        "            quad /= shrink\n",
        "            zoom *= shrink\n",
        "\n",
        "        # Crop.\n",
        "        border = max(int(np.round(1024 * 0.1 / zoom)), 3)\n",
        "        crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
        "        crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\n",
        "        if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
        "            img = img.crop(crop)\n",
        "            quad -= crop[0:2]\n",
        "\n",
        "        # Simulate super-resolution.\n",
        "        superres = int(np.exp2(np.ceil(np.log2(zoom))))\n",
        "        if superres > 1:\n",
        "            img = img.resize((img.size[0] * superres, img.size[1] * superres), PIL.Image.ANTIALIAS)\n",
        "            quad *= superres\n",
        "            zoom /= superres\n",
        "\n",
        "        # Pad.\n",
        "        pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
        "        pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\n",
        "        if max(pad) > border - 4:\n",
        "            pad = np.maximum(pad, int(np.round(1024 * 0.3 / zoom)))\n",
        "            img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
        "            h, w, _ = img.shape\n",
        "            y, x, _ = np.mgrid[:h, :w, :1]\n",
        "            mask = 1.0 - np.minimum(np.minimum(np.float32(x) / pad[0], np.float32(y) / pad[1]), np.minimum(np.float32(w-1-x) / pad[2], np.float32(h-1-y) / pad[3]))\n",
        "            blur = 1024 * 0.02 / zoom\n",
        "            img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
        "            img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\n",
        "            img = PIL.Image.fromarray(np.uint8(np.clip(np.round(img), 0, 255)), 'RGB')\n",
        "            quad += pad[0:2]\n",
        "            \n",
        "        # Transform.\n",
        "        img = img.transform((4096, 4096), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
        "        img = img.resize((1024, 1024), PIL.Image.ANTIALIAS)\n",
        "        img = np.asarray(img).transpose(2, 0, 1)\n",
        "        return img\n",
        "    list_images = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
        "    for image_name in list_images:\n",
        "      landmarks = retrieve_landmarks(folder_path+'/'+image_name)\n",
        "      if landmarks is not None:\n",
        "        img = PIL.Image.open(os.path.join(folder_path, image_name))\n",
        "        reshaped_img = process_func(img,landmarks[0])\n",
        "        data = Image.fromarray(np.transpose(reshaped_img,(1,2,0)))\n",
        "        data.save(folder_path+'/reshaped_'+image_name)"
      ],
      "metadata": {
        "id": "m0gv-2HWai-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshape_images('/content/gdrive/MyDrive/image_remplacement')"
      ],
      "metadata": {
        "id": "IR2v_Hiyaw4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dhD2AxSfyb55"
      }
    }
  ]
}