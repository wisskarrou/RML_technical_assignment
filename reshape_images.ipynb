{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeJ8pHUkaJiO",
    "outputId": "f5c948c1-b00f-47d4-cc84-55e9b9f29a94"
   },
   "source": [
    "Requirement:\n",
    "\n",
    "    pip install facenet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aI6DGX2kaNP6"
   },
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import os\n",
    "import PIL.Image\n",
    "import six.moves.queue as Queue\n",
    "import threading\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import threading\n",
    "import six.moves.queue as Queue\n",
    "import traceback\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoQvteOlaiR9"
   },
   "outputs": [],
   "source": [
    "def retrieve_landmarks(path_image):\n",
    "    # Create face detector\n",
    "    mtcnn = MTCNN(keep_all=True, device='cuda:0')\n",
    "\n",
    "    # Load a single image and display\n",
    "    img = Image.open(path_image)\n",
    "    img = np.asarray(img)\n",
    "    frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    frame = Image.fromarray(frame)\n",
    "\n",
    "    # Detect face\n",
    "    boxes, probs, landmarks = mtcnn.detect(frame, landmarks=True)\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0gv-2HWai-U"
   },
   "outputs": [],
   "source": [
    "def reshape_images(folder_path):\n",
    "    import scipy.ndimage\n",
    "\n",
    "    def rot90(v):\n",
    "        return np.array([-v[1], v[0]])\n",
    "\n",
    "    def process_func(img,lm):\n",
    "        # Choose oriented crop rectangle.\n",
    "        eye_avg = (lm[0] + lm[1]) * 0.5 + 0.5\n",
    "        mouth_avg = (lm[3] + lm[4]) * 0.5 + 0.5\n",
    "        eye_to_eye = lm[1] - lm[0]\n",
    "        eye_to_mouth = mouth_avg - eye_avg\n",
    "        x = eye_to_eye - rot90(eye_to_mouth)\n",
    "        x /= np.hypot(*x)\n",
    "        x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
    "        y = rot90(x)\n",
    "        c = eye_avg + eye_to_mouth * 0.1\n",
    "        quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
    "        zoom = 1024 / (np.hypot(*x) * 2)\n",
    "\n",
    "        # Shrink.\n",
    "        shrink = int(np.floor(0.5 / zoom))\n",
    "        if shrink > 1:\n",
    "            size = (int(np.round(float(img.size[0]) / shrink)), int(np.round(float(img.size[1]) / shrink)))\n",
    "            img = img.resize(size, PIL.Image.ANTIALIAS)\n",
    "            quad /= shrink\n",
    "            zoom *= shrink\n",
    "\n",
    "        # Crop.\n",
    "        border = max(int(np.round(1024 * 0.1 / zoom)), 3)\n",
    "        crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
    "        crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\n",
    "        if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
    "            img = img.crop(crop)\n",
    "            quad -= crop[0:2]\n",
    "\n",
    "        # Simulate super-resolution.\n",
    "        superres = int(np.exp2(np.ceil(np.log2(zoom))))\n",
    "        if superres > 1:\n",
    "            img = img.resize((img.size[0] * superres, img.size[1] * superres), PIL.Image.ANTIALIAS)\n",
    "            quad *= superres\n",
    "            zoom /= superres\n",
    "\n",
    "        # Pad.\n",
    "        pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
    "        pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\n",
    "        if max(pad) > border - 4:\n",
    "            pad = np.maximum(pad, int(np.round(1024 * 0.3 / zoom)))\n",
    "            img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
    "            h, w, _ = img.shape\n",
    "            y, x, _ = np.mgrid[:h, :w, :1]\n",
    "            mask = 1.0 - np.minimum(np.minimum(np.float32(x) / pad[0], np.float32(y) / pad[1]), np.minimum(np.float32(w-1-x) / pad[2], np.float32(h-1-y) / pad[3]))\n",
    "            blur = 1024 * 0.02 / zoom\n",
    "            img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
    "            img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\n",
    "            img = PIL.Image.fromarray(np.uint8(np.clip(np.round(img), 0, 255)), 'RGB')\n",
    "            quad += pad[0:2]\n",
    "            \n",
    "        # Transform.\n",
    "        img = img.transform((4096, 4096), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
    "        img = img.resize((1024, 1024), PIL.Image.ANTIALIAS)\n",
    "        img = np.asarray(img).transpose(2, 0, 1)\n",
    "        return img\n",
    "    list_images = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    for image_name in list_images:\n",
    "        landmarks = retrieve_landmarks(folder_path+'/'+image_name)\n",
    "        if landmarks is not None:\n",
    "            img = PIL.Image.open(os.path.join(folder_path, image_name))\n",
    "            reshaped_img = process_func(img,landmarks[0])\n",
    "            data = Image.fromarray(np.transpose(reshaped_img,(1,2,0)))\n",
    "            data.save(folder_path+'/reshaped_'+image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IR2v_Hiyaw4G"
   },
   "outputs": [],
   "source": [
    "folder_path = 'Panel_utkface'#panel utkface is a manually chosen panel of 120 photos of UTKFace (not normalized, with various positions of facial landmarks)\n",
    "reshape_images(folder_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
